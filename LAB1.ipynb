{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjtqMyf4XGom"
      },
      "outputs": [],
      "source": [
        "#!tar -xvf data.tar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "def extract_df(Folder):\n",
        "    data_frames = []\n",
        "\n",
        "    for filename in os.listdir(os.path.join('data', Folder)):\n",
        "          with open(os.path.join('data', Folder, filename), 'r') as f:\n",
        "              reader = csv.reader(f, delimiter='|')\n",
        "              data = [row for row in reader]\n",
        "              headers = data[0]\n",
        "              df = pd.DataFrame(data[1:], columns=headers)\n",
        "              df['index'] = os.path.join(Folder, filename)\n",
        "              if (df['SepsisLabel'] == '1').any():\n",
        "                  index_of_first_1 = (df['SepsisLabel'] == '1').idxmax()\n",
        "                  df['label'] = 1\n",
        "                  df = df.iloc[:index_of_first_1+1]\n",
        "              else:\n",
        "                  df['label'] = 0\n",
        "              data_frames.append(df)\n",
        "\n",
        "    df_all = pd.concat(data_frames, ignore_index=True)\n",
        "    df_all.loc[:, df_all.columns != 'index'] = df_all.loc[:, df_all.columns != 'index'].apply(pd.to_numeric, errors='coerce')\n",
        "    return df_all\n",
        "\n",
        "train_df = extract_df('train')\n",
        "test_df = extract_df('test')\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "test_df.to_csv('test.csv', index=False)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6HNrZ24nwt0O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "dc6aa135-0315-4356-edfb-07dbb1502f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nimport os\\nimport csv\\nimport pandas as pd\\n\\ndef extract_df(Folder):\\n    data_frames = []\\n\\n    for filename in os.listdir(os.path.join('data', Folder)):\\n          with open(os.path.join('data', Folder, filename), 'r') as f:\\n              reader = csv.reader(f, delimiter='|')\\n              data = [row for row in reader]\\n              headers = data[0]\\n              df = pd.DataFrame(data[1:], columns=headers)\\n              df['index'] = os.path.join(Folder, filename)\\n              if (df['SepsisLabel'] == '1').any():\\n                  index_of_first_1 = (df['SepsisLabel'] == '1').idxmax()\\n                  df['label'] = 1\\n                  df = df.iloc[:index_of_first_1+1]\\n              else:\\n                  df['label'] = 0\\n              data_frames.append(df)\\n\\n    df_all = pd.concat(data_frames, ignore_index=True)\\n    df_all.loc[:, df_all.columns != 'index'] = df_all.loc[:, df_all.columns != 'index'].apply(pd.to_numeric, errors='coerce')\\n    return df_all\\n\\ntrain_df = extract_df('train')\\ntest_df = extract_df('test')\\ntrain_df.to_csv('train.csv', index=False)\\ntest_df.to_csv('test.csv', index=False)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "import zipfile\n",
        "\n",
        "# Specify the file names and paths\n",
        "file1 = '/content/train.csv'\n",
        "file2 = '/content/test.csv'\n",
        "zip_path = '/content/gdrive/My Drive/train_test_csv.zip'\n",
        "\n",
        "# Create a ZipFile object and add the files to it\n",
        "with zipfile.ZipFile(zip_path, 'w') as zip_file:\n",
        "    zip_file.write(file1)\n",
        "    zip_file.write(file2)\n",
        "import os\n",
        "\n",
        "# Check that the file was created\n",
        "if os.path.exists(zip_path):\n",
        "    print('File saved successfully to Google Drive')\n",
        "else:\n",
        "    print('File not found')\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "C9gCGuAYCgKb",
        "outputId": "1a967d7d-6145-4629-8d18-6c46cf1bd726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom google.colab import drive\\n#drive.mount('/content/gdrive')\\nimport zipfile\\n\\n# Specify the file names and paths\\nfile1 = '/content/train.csv'\\nfile2 = '/content/test.csv'\\nzip_path = '/content/gdrive/My Drive/train_test_csv.zip'\\n\\n# Create a ZipFile object and add the files to it\\nwith zipfile.ZipFile(zip_path, 'w') as zip_file:\\n    zip_file.write(file1)\\n    zip_file.write(file2)\\nimport os\\n\\n# Check that the file was created\\nif os.path.exists(zip_path):\\n    print('File saved successfully to Google Drive')\\nelse:\\n    print('File not found')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "zip_path = '/content/gdrive/MyDrive/train_test_csv.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_file:\n",
        "    zip_file.extractall('/content/train_test_csv')\n",
        "\n",
        "\n",
        "train_path = '/content/train_test_csv/content/train.csv'\n",
        "test_path = '/content/train_test_csv/content/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n"
      ],
      "metadata": {
        "id": "LPO_ofFDDjvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8874c8-46dd-4692-892c-f16a7e0bc670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def grouped(df_to_groupby):\n",
        "    df_to_groupby.drop(columns=['SepsisLabel'])\n",
        "\n",
        "    to_stats = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2',\n",
        "          'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
        "          'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
        "          'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
        "          'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
        "          'Fibrinogen', 'Platelets', 'Age', 'Gender', 'HospAdmTime', 'ICULOS','label']\n",
        "\n",
        "    import numpy as np\n",
        "\n",
        "    # Group by index column and apply multiple aggregation functions\n",
        "    agg_dict = {'HR': ['mean', 'std'],\n",
        "                'O2Sat': ['mean', 'std'],\n",
        "                'Temp': ['mean', 'std'],\n",
        "                'SBP': ['mean', 'std'],\n",
        "                'MAP': ['mean',  'std'],\n",
        "                'DBP': ['mean', 'std'],\n",
        "                'Resp': ['mean', 'std'],\n",
        "                'EtCO2': ['mean', 'std'],\n",
        "\n",
        "                'BaseExcess': ['mean', 'std'],\n",
        "                'HCO3': ['mean', 'std'],\n",
        "                'FiO2': ['mean', 'std'],\n",
        "                'pH': ['mean', 'std'],\n",
        "                'PaCO2': ['mean', 'std'],\n",
        "                'SaO2': ['mean', 'std'],\n",
        "                'AST': ['mean', 'std'],\n",
        "                'BUN': ['mean', 'std'],\n",
        "\n",
        "                'Alkalinephos': ['mean','std'],\n",
        "                'Calcium': ['mean', 'std'],\n",
        "                'Chloride': ['mean', 'std'],\n",
        "                'Creatinine': ['mean', 'std'],\n",
        "                'Bilirubin_direct': ['mean', 'std'],\n",
        "\n",
        "                'Glucose': ['mean', 'std'],\n",
        "                'Lactate': ['mean',  'std'],\n",
        "                'Magnesium': ['mean', 'std'],\n",
        "                'Phosphate': ['mean', 'std'],\n",
        "                'Potassium': ['mean', 'std'],\n",
        "\n",
        "                'Bilirubin_total': ['mean', 'std'],\n",
        "                'TroponinI': ['mean', 'std'],\n",
        "                'Hct': ['mean', 'std'],\n",
        "                'Hgb': ['mean', 'std'],\n",
        "                'PTT': ['mean', 'std'],\n",
        "                'WBC': ['mean', 'std'],\n",
        "\n",
        "                'Fibrinogen': ['mean', 'std'],\n",
        "                'Platelets': ['mean', 'std'],\n",
        "                'Age': ['mean'],\n",
        "                'Gender': ['mean'],\n",
        "                'HospAdmTime': ['mean'],\n",
        "                'ICULOS': ['mean', 'std'],\n",
        "                'label': ['mean'],\n",
        "                }\n",
        "\n",
        "    grouped_df = df_to_groupby.groupby('index')[to_stats].agg(agg_dict)\n",
        "\n",
        "    # Flatten column names in the resulting DataFrame\n",
        "    grouped_df.columns = ['_'.join(col).strip() for col in grouped_df.columns.values]\n",
        "\n",
        "    # Reset the index to make the groupby column a regular column\n",
        "    grouped_df = grouped_df.reset_index()\n",
        "    grouped_df = grouped_df.drop(columns=['index'])\n",
        "    return grouped_df\n",
        "\n",
        "\n",
        "train_grouped = grouped(train_df)\n",
        "test_grouped = grouped(test_df)"
      ],
      "metadata": {
        "id": "4IqvgK2k5bnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def impute_knn(df_to_impute):\n",
        "    dropped = df_to_impute['label_mean']\n",
        "    df_to_impute = df_to_impute.drop(columns =['label_mean'])\n",
        "\n",
        "    missing_cols = [col for col in df_to_impute.columns if df_to_impute[col].isnull().any()]\n",
        "    missing_cols_idx = [df_to_impute.columns.get_loc(col) for col in missing_cols]\n",
        "\n",
        "    imputer = KNNImputer(n_neighbors=3)\n",
        "    df_imputed = pd.DataFrame(imputer.fit_transform(df_to_impute), columns=df_to_impute.columns)\n",
        "    return pd.concat([df_imputed, dropped], axis=1)\n",
        ""
      ],
      "metadata": {
        "id": "QSgSsW3SVqOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "try1 = ['HR_mean', 'O2Sat_mean', 'Temp_mean', 'MAP_mean',  'Resp_mean', 'Hgb_mean',\n",
        "       'WBC_mean', 'HospAdmTime_mean', 'ICULOS_mean',\n",
        "       'ICULOS_std','label_mean']\n",
        "\n",
        "try2 = ['HR_mean', 'O2Sat_mean', 'Temp_mean', 'MAP_mean',  'Resp_mean','Chloride_mean', 'Lactate_mean', 'Hct_mean', 'Hgb_mean',\n",
        "       'WBC_mean', 'Platelets_std', 'HospAdmTime_mean', 'ICULOS_mean',\n",
        "       'ICULOS_std','label_mean']\n",
        "train_grouped_copy = impute_knn(train_grouped)\n",
        "test_grouped_copy = impute_knn(test_grouped)\n",
        "\n",
        "X_train = train_grouped_copy.drop('label_mean', axis=1)\n",
        "y_train = train_grouped_copy['label_mean']\n",
        "\n",
        "X_test = test_grouped_copy.drop('label_mean', axis=1)\n",
        "y_test = test_grouped_copy['label_mean']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ANzFqEMVDwjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict the train data\n",
        "y_pred_train = rf.predict(X_train)\n",
        "\n",
        "f1_train = f1_score(y_pred_train, y_train)\n",
        "\n",
        "# Predict the test data\n",
        "y_pred_test = rf.predict(X_test)\n",
        "\n",
        "f1_test = f1_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"F1 train score:\", f1_train)\n",
        "print(\"F1 test score:\", f1_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkIPP96dJvj6",
        "outputId": "08fdb1b4-8cc8-4caf-bc09-2d647cb67efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 train score: 0.9996465182043125\n",
            "F1 test score: 0.6764946764946764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# create neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=0)\n",
        "\n",
        "y_pred_nn = model.predict(X_test)\n",
        "y_pred_train = model.predict(X_train)\n",
        "\n",
        "threshold = 0.55\n",
        "binary_predictions_test = np.where(y_pred_nn > threshold, 1, 0)\n",
        "binary_predictions_train = np.where(y_pred_train > threshold, 1, 0)\n",
        "\n",
        "f1_nn = f1_score(y_test, binary_predictions_test)\n",
        "f1_train = f1_score(y_train, binary_predictions_train)\n",
        "\n",
        "print(f\"F1 score for neural network train: {f1_train:.4f}\")\n",
        "print(f\"F1 score for neural network test: {f1_nn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMvknp0bL2WX",
        "outputId": "50dd4cbf-3d5b-4aa1-c276-b293fd87bf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "625/625 [==============================] - 2s 3ms/step\n",
            "F1 score for neural network train: 0.6940\n",
            "F1 score for neural network test: 0.6596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "gbm = GradientBoostingClassifier(learning_rate=0.12, subsample=0.8, n_estimators=200, random_state=42)\n",
        "\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict the train data\n",
        "y_pred_train = gbm.predict(X_train)\n",
        "\n",
        "f1_train = f1_score(y_pred_train, y_train)\n",
        "\n",
        "# Predict the test data\n",
        "y_pred_test = gbm.predict(X_test)\n",
        "\n",
        "f1_test = f1_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"F1 train score:\", f1_train)\n",
        "print(\"F1 test score:\", f1_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YByxZCLuRaSW",
        "outputId": "63a9ac4f-3813-4d38-e274-89c1213d81f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 train score: 0.785831960461285\n",
            "F1 test score: 0.6744366744366744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# create DMatrix for training and test sets\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "\n",
        "# set XGBoost parameters\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'eta': 0.001, # learning rate\n",
        "    'subsample': 0.5, # subsampling ratio of training data\n",
        "    'seed': 42,\n",
        "    'sampling_method': 'uniform'\n",
        "}\n",
        "\n",
        "# train\n",
        "xgb_model = xgb.train(params=params, dtrain=dtrain, num_boost_round=1000)\n",
        "\n",
        "y_pred_test = xgb_model.predict(dtest)\n",
        "y_pred_train = xgb_model.predict(dtrain)\n",
        "\n",
        "range_t = np.arange(0, 1, 0.001)\n",
        "max = 0\n",
        "max_ther = 0\n",
        "for i in range_t:\n",
        "  binary_predictions = np.where(y_pred_test > i, 1, 0)\n",
        "  f1 = f1_score(y_test, binary_predictions)\n",
        "  binary_predictions_train = np.where(y_pred_train > i, 1, 0)\n",
        "\n",
        "  f1_train =  f1_score(y_train, binary_predictions_train)\n",
        "  if max < f1:\n",
        "    max = f1\n",
        "    max_ther = i\n",
        "    max_train = f1_train\n",
        "\n",
        "print(f\"F1 score for xnm test: {max:.4f}, train {max_train} with threshold {max_ther}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSVeWLEQcXCN",
        "outputId": "35f02098-deb1-46b5-9095-12198c9053ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score for xnm test: 0.7023, train 0.8196214754731557 with threshold 0.367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "def make_comp_model(train_grouped, test_grouped):\n",
        "  df_comp = pd.concat([train_grouped, test_grouped], ignore_index=True)\n",
        "  comp_grouped_copy = impute_knn(df_comp[try2])\n",
        "\n",
        "  X_comp = comp_grouped_copy.drop('label_mean', axis=1)\n",
        "  y_comp = comp_grouped_copy['label_mean']\n",
        "\n",
        "  dcomp = xgb.DMatrix(X_comp, label=y_comp)\n",
        "\n",
        "\n",
        "  # set XGBoost parameters\n",
        "  params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'eta': 0.001, # learning rate\n",
        "    'subsample': 0.5, # subsampling ratio of training data\n",
        "    'seed': 42, # random seed\n",
        "    'sampling_method': 'uniform'\n",
        "  }\n",
        "\n",
        "  # train XGBoost model\n",
        "  xgb_model = xgb.train(params=params, dtrain=dcomp, num_boost_round=1000)\n",
        "  joblib.dump(xgb_model, 'comp_xgb_model.joblib')\n",
        "\n",
        "make_comp_model(train_grouped, test_grouped)"
      ],
      "metadata": {
        "id": "R3vIKtVqSHA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os, csv\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# predict.py\n",
        "\n",
        "def extract_df_comp(Folder):\n",
        "    data_frames = []\n",
        "\n",
        "    for filename in os.listdir(Folder):\n",
        "          with open(os.path.join('data', Folder, filename), 'r') as f:\n",
        "              reader = csv.reader(f, delimiter=',')\n",
        "              data = [row for row in reader]\n",
        "              headers = data[0]\n",
        "              df = pd.DataFrame(data[1:], columns=headers)\n",
        "              df['index'] = filename\n",
        "\n",
        "              data_frames.append(df)\n",
        "\n",
        "    df_all = pd.concat(data_frames, ignore_index=True)\n",
        "    df_all.loc[:, df_all.columns != 'index'] = df_all.loc[:, df_all.columns != 'index'].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    return df_all\n",
        "\n",
        "def grouped_comp(df_to_groupby):\n",
        "    to_stats = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2',\n",
        "          'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
        "          'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
        "          'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
        "          'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
        "          'Fibrinogen', 'Platelets', 'Age', 'Gender', 'HospAdmTime', 'ICULOS']\n",
        "\n",
        "\n",
        "    # Group by index column and apply multiple aggregation functions\n",
        "    agg_dict = {'HR': ['mean', 'std'],\n",
        "                'O2Sat': ['mean', 'std'],\n",
        "                'Temp': ['mean', 'std'],\n",
        "                'SBP': ['mean', 'std'],\n",
        "                'MAP': ['mean',  'std'],\n",
        "                'DBP': ['mean', 'std'],\n",
        "                'Resp': ['mean', 'std'],\n",
        "                'EtCO2': ['mean', 'std'],\n",
        "\n",
        "                'BaseExcess': ['mean', 'std'],\n",
        "                'HCO3': ['mean', 'std'],\n",
        "                'FiO2': ['mean', 'std'],\n",
        "                'pH': ['mean', 'std'],\n",
        "                'PaCO2': ['mean', 'std'],\n",
        "                'SaO2': ['mean', 'std'],\n",
        "                'AST': ['mean', 'std'],\n",
        "                'BUN': ['mean', 'std'],\n",
        "\n",
        "                'Alkalinephos': ['mean','std'],\n",
        "                'Calcium': ['mean', 'std'],\n",
        "                'Chloride': ['mean', 'std'],\n",
        "                'Creatinine': ['mean', 'std'],\n",
        "                'Bilirubin_direct': ['mean', 'std'],\n",
        "\n",
        "                'Glucose': ['mean', 'std'],\n",
        "                'Lactate': ['mean',  'std'],\n",
        "                'Magnesium': ['mean', 'std'],\n",
        "                'Phosphate': ['mean', 'std'],\n",
        "                'Potassium': ['mean', 'std'],\n",
        "\n",
        "                'Bilirubin_total': ['mean', 'std'],\n",
        "                'TroponinI': ['mean', 'std'],\n",
        "                'Hct': ['mean', 'std'],\n",
        "                'Hgb': ['mean', 'std'],\n",
        "                'PTT': ['mean', 'std'],\n",
        "                'WBC': ['mean', 'std'],\n",
        "\n",
        "                'Fibrinogen': ['mean', 'std'],\n",
        "                'Platelets': ['mean', 'std'],\n",
        "                'Age': ['mean'],\n",
        "                'Gender': ['mean'],\n",
        "                'HospAdmTime': ['mean'],\n",
        "                'ICULOS': ['mean', 'std'],\n",
        "                }\n",
        "\n",
        "    grouped_df = df_to_groupby.groupby('index')[to_stats].agg(agg_dict)\n",
        "\n",
        "    # Flatten column names in the resulting DataFrame\n",
        "    grouped_df.columns = ['_'.join(col).strip() for col in grouped_df.columns.values]\n",
        "\n",
        "    # Reset the index to make the groupby column a regular column\n",
        "    grouped_df = grouped_df.reset_index()\n",
        "    return grouped_df\n",
        "\n",
        "def impute_knn_comp(df_to_impute):\n",
        "    missing_cols = [col for col in df_to_impute.columns if df_to_impute[col].isnull().any()]\n",
        "    missing_cols_idx = [df_to_impute.columns.get_loc(col) for col in missing_cols]\n",
        "\n",
        "    imputer = KNNImputer(n_neighbors=3)\n",
        "    df_imputed = pd.DataFrame(imputer.fit_transform(df_to_impute), columns=df_to_impute.columns)\n",
        "    return df_imputed\n",
        "\n",
        "\n",
        "# Define the path to the patient tables folder as the first argument in the command line\n",
        "folder_path = '/content/data/train'#sys.argv[1]\n",
        "\n",
        "test_df = extract_df_comp(folder_path)\n",
        "test_df_grouped = grouped_comp(test_df)\n",
        "\n",
        "best_cols = ['HR_mean', 'O2Sat_mean', 'Temp_mean', 'MAP_mean',  'Resp_mean','Chloride_mean', 'Lactate_mean', 'Hct_mean', 'Hgb_mean',\n",
        "      'WBC_mean', 'Platelets_std', 'HospAdmTime_mean', 'ICULOS_mean',\n",
        "      'ICULOS_std']\n",
        "test_grouped_copy = impute_knn_comp(test_df_grouped[best_cols])\n",
        "\n",
        "\n",
        "xgb_loaded = joblib.load('comp_xgb_model.joblib')\n",
        "dcomp_test = xgb.DMatrix(test_grouped_copy)\n",
        "y_pred = xgb_loaded.predict(dcomp_test)\n",
        "binary_predictions = np.where(y_pred > 0.37, 1, 0)\n",
        "\n",
        "new_df = pd.DataFrame({'id': test_df_grouped['index'], 'prediction': binary_predictions})\n",
        "new_df.to_csv('prediction.csv', index=False)\n"
      ],
      "metadata": {
        "id": "oWz8EjFrKdXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_df = pd.read_csv('/content/prediction.csv')\n",
        "y_pred_test = test_df['prediction']\n",
        "y_test = y_train\n",
        "f1_test = f1_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"F1 train score:\", f1_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSR2bElJXGdB",
        "outputId": "a3292cdc-aeee-4b76-8989-80b0e3b0e749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 train score: 0.7732986562635457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "# copy the zip file to current directory\n",
        "drive.mount('/content/drive')\n",
        "zip_file_path = '/content/drive/MyDrive/folder_to_zip.zip'\n",
        "\n",
        "shutil.copy(zip_file_path, '/content')\n",
        "\n",
        "# to load the zip file from drive:\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip:\n",
        "    zip.extractall('/content/data')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXP7ifdSFfgP",
        "outputId": "88146f23-36a2-4cae-d940-54f5dc4546f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}